{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Fail\n",
    "\n",
    "Import required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "DATA_FILE = \"../data/headlines.txt\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `requests` to download latest headlines with `BeautifulSoup`, then dedupe any new headlines from the existing headline dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = requests.get(\"https://www.dailymail.co.uk/news/headlines/index.html\")\n",
    "if response.ok:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    sidebar = soup.select(\"ul.link-bogr2 li span.pufftext strong\")\n",
    "    new_headlines = []\n",
    "    for headline in sidebar:\n",
    "        new_headlines.append(headline.get_text(strip=True))\n",
    "    \n",
    "    with open(DATA_FILE, \"r\") as file:\n",
    "        existing_headlines = file.readlines()\n",
    "        existing_headlines = [line.strip() for line in existing_headlines]\n",
    "        \n",
    "    new_headlines = [s for s in new_headlines if s not in existing_headlines]\n",
    "\n",
    "    with open(DATA_FILE, \"a\") as file:\n",
    "        for s in new_headlines:\n",
    "            file.write(s + \"\\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"Error: \", response.status_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in existing headlines from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "filename = DATA_FILE\n",
    "\n",
    "with open(filename, \"r\") as file:\n",
    "    existing_headlines = file.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through file to identify NER's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_counts = Counter()\n",
    "for string in existing_headlines:\n",
    "    doc = nlp(string.strip())\n",
    "    for ent in doc.ents:\n",
    "        entity_counts[(ent.text, ent.label_)] += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and display the data\n",
    "\n",
    "1. Create a Pandas DataFrame from the Counter object\n",
    "2. Split the \"Entity\" column into two separate columns \"Text\" and \"Label\"\n",
    "3. Drop the \"Entity\" column\n",
    "4. Filter out results to only show PERSON, ORG, GPE (General Point of Interest),\n",
    "   and WORK_OF_ART entities.\n",
    "5. Sort DataFrame by Count (largest first), then Text, alphabetically.\n",
    "6. Reduce the table to the top 20 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.DataFrame(entity_counts.items(), columns=['Entity', 'Count'], index=None)\n",
    "df[['Text', 'Label']] = pd.DataFrame(df['Entity'].tolist(), index=df.index)\n",
    "df = df.drop('Entity', axis=1)\n",
    "df = df.loc[df['Label'].isin(['PERSON', 'ORG', 'GPE', 'WORK_OF_ART'])]\n",
    "df = df.sort_values(by=['Count', 'Text'], ascending=[False, True])\n",
    "df = df.head(20)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
