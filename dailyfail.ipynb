{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Fail\n",
    "\n",
    "Import required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "DATA_FILE = \"headlines.txt\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `requests` to download latest headlines with `BeautifulSoup`, then dedupe any new headlines from the existing headline dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = requests.get(\"https://www.dailymail.co.uk/news/headlines/index.html\")\n",
    "if response.ok:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    sidebar = soup.select(\"ul.link-bogr2 li span.pufftext strong\")\n",
    "    new_headlines = []\n",
    "    for headline in sidebar:\n",
    "        new_headlines.append(headline.get_text(strip=True))\n",
    "    \n",
    "    with open(DATA_FILE, \"r\") as file:\n",
    "        existing_headlines = file.readlines()[-250:]\n",
    "        existing_headlines = [line.strip() for line in existing_headlines]\n",
    "        \n",
    "    new_headlines = [s for s in new_headlines if s not in existing_headlines]\n",
    "\n",
    "    with open(DATA_FILE, \"a\") as file:\n",
    "        for s in new_headlines:\n",
    "            file.write(s + \"\\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"Error: \", response.status_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in existing headlines from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "filename = DATA_FILE\n",
    "\n",
    "with open(filename, \"r\") as file:\n",
    "    existing_headlines = file.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through file to identify NER's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_counts = Counter()\n",
    "for string in existing_headlines:\n",
    "    doc = nlp(string.strip())\n",
    "    for ent in doc.ents:\n",
    "        entity_counts[(ent.text, ent.label_)] += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a Pandas DataFrame from the Counter object\n",
    "2. Split the \"Entity\" column into two separate columns \"Text\" and \"Label\"\n",
    "3. Drop the \"Entity\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>Oscars</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>11</td>\n",
       "      <td>Vanity Fair</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7</td>\n",
       "      <td>Academy Awards</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6</td>\n",
       "      <td>BBC</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>Oscar</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>Beverly Hills</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>Florence Pugh</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>5</td>\n",
       "      <td>Joey Essex</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Best Picture</td>\n",
       "      <td>WORK_OF_ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>Brendan Fraser</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>4</td>\n",
       "      <td>Elvis</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>Jamie Lee Curtis</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>4</td>\n",
       "      <td>LA</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Michelle Yeoh</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>4</td>\n",
       "      <td>Nile Wilson</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>Oscar Party</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>Will Smith</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>Angela Bassett</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>3</td>\n",
       "      <td>Austin Butler</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Count              Text        Label\n",
       "20      11            Oscars          ORG\n",
       "40      11       Vanity Fair          ORG\n",
       "71       7    Academy Awards          ORG\n",
       "14       7         Hollywood          GPE\n",
       "124      6               BBC          ORG\n",
       "50       6             Oscar       PERSON\n",
       "42       5     Beverly Hills          GPE\n",
       "34       5     Florence Pugh       PERSON\n",
       "132      5        Joey Essex       PERSON\n",
       "7        4      Best Picture  WORK_OF_ART\n",
       "8        4    Brendan Fraser       PERSON\n",
       "190      4             Elvis       PERSON\n",
       "22       4  Jamie Lee Curtis       PERSON\n",
       "386      4                LA          GPE\n",
       "5        4     Michelle Yeoh       PERSON\n",
       "134      4       Nile Wilson          ORG\n",
       "41       4       Oscar Party          ORG\n",
       "10       4        Will Smith       PERSON\n",
       "77       3    Angela Bassett       PERSON\n",
       "189      3     Austin Butler       PERSON"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.DataFrame(entity_counts.items(), columns=['Entity', 'Count'], index=None)\n",
    "df[['Text', 'Label']] = pd.DataFrame(df['Entity'].tolist(), index=df.index)\n",
    "df = df.drop('Entity', axis=1)\n",
    "df = df.loc[df['Label'].isin(['PERSON', 'ORG', 'GPE', 'WORK_OF_ART'])]\n",
    "df = df.sort_values(by=['Count', 'Text'], ascending=[False, True])\n",
    "df = df.head(20)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
